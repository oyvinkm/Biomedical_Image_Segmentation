{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from Image_Functions import slicing, crop_to_size\r\n",
    "from datasetModule import Set\r\n",
    "from torch import nn\r\n",
    "import Model\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most of the functionallity is stored in module files. \r\n",
    "The data consist of Images with 3 channels and segmentation images with 2 channels.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#hyper parameters\r\n",
    "batch_size = 2\r\n",
    "learning_rate = 0.01\r\n",
    "num_epochs = 4\r\n",
    "weight_tensor = torch.tensor([1.0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\"Need to specify the local path on computer\"\r\n",
    "dir_path = \"../Cropped_Task3/\"\r\n",
    "\r\n",
    "'Splitting the data into 30% test and 70% training.'\r\n",
    "train_set, test_set = train_test_split(Set(dir_path, sub_dir = 'crop_sub-23'), test_size=0.2, random_state=25)\r\n",
    "\r\n",
    "size = (256,288,176)\r\n",
    "train_set = crop_to_size(train_set, size)\r\n",
    "test_set = crop_to_size(test_set, size)\r\n",
    "\r\n",
    "'Load training and test set, batch size my vary'\r\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\r\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\r\n",
    "test_set = None\r\n",
    "train_set = None\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../Cropped_Task3/'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9f7544abf39e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m'Splitting the data into 30% test and 70% training.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'crop_sub-23'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m288\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m176\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aske\\Desktop\\Bachelor\\Biomedical_Image_Segmentation\\aske_code\\datasetModule.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_path, to_tensor, sub_dir)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_dir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../Cropped_Task3/'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, image_set in enumerate(test_loader):\r\n",
    "    image = image_set['data'].to(device)\r\n",
    "    labels = image_set['seg'].to(device)\r\n",
    "    print(\"image shape =\", image.shape)\r\n",
    "    print(\"labels shape =\", labels.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'Run the CNN'\r\n",
    "model = Model.CNN(3).to(device)\r\n",
    "string = 'CrossEntropyLoss'\r\n",
    "criterion = nn.CrossEntropyLoss(weight=weight_tensor) if string == 'CrossEntropyLoss' else nn.BCELoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "n_total_steps = len(train_loader)\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, image_set in enumerate(train_loader):\r\n",
    "        image = image_set['data'].to(device)\r\n",
    "        labels = image_set['seg'].to(device)\r\n",
    "        if string == 'CrossEntropyLoss':\r\n",
    "            outputs = model(image)#.squeeze(1)\r\n",
    "            labels = labels.squeeze(1)#.squeeze(1)\r\n",
    "        else:\r\n",
    "            outputs = model(image)\r\n",
    "        \r\n",
    "        print(\"outputs shape = \", outputs.shape)\r\n",
    "        print(\"labels shape = \\t\", labels.shape)\r\n",
    "\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "        print(1)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        print(2)\r\n",
    "        loss.backward()\r\n",
    "        print(3)\r\n",
    "        optimizer.step()\r\n",
    "        print(4)\r\n",
    "        if (i+1) % 1 == 0:\r\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!jupyter nbconvert --to script *.ipynb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "m = nn.BatchNorm3d(100)\r\n",
    "# Without Learnable Parameters\r\n",
    "m = nn.BatchNorm3d(100, affine=False)\r\n",
    "input = torch.randn(20, 100, 1, 1, 1)\r\n",
    "output = m(input)\r\n",
    "\r\n",
    "\r\n",
    "print(output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "examples = iter(train_loader)\r\n",
    "samples = examples.next()\r\n",
    "m = nn.BatchNorm3d(3)\r\n",
    "\r\n",
    "print(samples['data'].shape)\r\n",
    "\r\n",
    "image1 = m(samples['data'])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fe43c643eedcd1f687e99e6ead277e97843d429b5f47c8612e5d5f5c5d388128"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}